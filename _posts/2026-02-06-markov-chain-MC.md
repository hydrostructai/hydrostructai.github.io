---
title: "Markov Chain Monte Carlo (MCMC): Overview & Applications / Tá»•ng quan & á»¨ng dá»¥ng"
author_profile: true
author_name: "HST.AI"
date: 2026-02-06 08:00:00 +0700
layout: single
toc: true
toc_sticky: true
toc_label: "ğŸ“‘ Content / Má»¥c Lá»¥c"
categories:
  - Data Science
  - Algorithms
  - Engineering
tags:
  [
    MCMC,
    Monte Carlo,
    Bayesian Statistics,
    Python,
    Algorithm
  ]
---

Markov Chain Monte Carlo (MCMC) is a powerful class of algorithms for sampling from probability distributions. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution to approximate complex integrals or understand posterior distributions in Bayesian statistics.  
*Markov Chain Monte Carlo (MCMC) lÃ  má»™t lá»›p cÃ¡c thuáº­t toÃ¡n láº¥y máº«u tá»« phÃ¢n phá»‘i xÃ¡c suáº¥t. Báº±ng cÃ¡ch xÃ¢y dá»±ng má»™t chuá»—i Markov cÃ³ phÃ¢n phá»‘i cÃ¢n báº±ng (equilibrium distribution) mong muá»‘n, ta cÃ³ thá»ƒ láº¥y máº«u tá»« phÃ¢n phá»‘i Ä‘Ã³ Ä‘á»ƒ xáº¥p xá»‰ cÃ¡c tÃ­ch phÃ¢n phá»©c táº¡p hoáº·c hiá»ƒu rÃµ hÆ¡n vá» tÃ­nh cháº¥t cá»§a phÃ¢n phá»‘i háº­u nghiá»‡m (posterior) trong thá»‘ng kÃª Bayes.*

---

## 1. Markov Chain (Chuá»—i Markov)

A Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.  
*Chuá»—i Markov lÃ  má»™t mÃ´ hÃ¬nh ngáº«u nhiÃªn mÃ´ táº£ má»™t chuá»—i cÃ¡c biáº¿n cá»‘ kháº£ dÄ©, trong Ä‘Ã³ xÃ¡c suáº¥t cá»§a má»—i biáº¿n cá»‘ chá»‰ phá»¥ thuá»™c vÃ o tráº¡ng thÃ¡i Ä‘áº¡t Ä‘Æ°á»£c trong biáº¿n cá»‘ trÆ°á»›c Ä‘Ã³.*

*   **Markov Property / TÃ­nh cháº¥t Markov**: The future depends only on the present, not on the past.  
    *TÆ°Æ¡ng lai chá»‰ phá»¥ thuá»™c vÃ o hiá»‡n táº¡i, khÃ´ng phá»¥ thuá»™c vÃ o quÃ¡ khá»©.*
    $$P(X_{n+1} | X_n, X_{n-1}, ..., X_0) = P(X_{n+1} | X_n)$$
*   **Transition Matrix / Ma tráº­n chuyá»ƒn tráº¡ng thÃ¡i**: Describes the probabilities of moving from one state to another.  
    *MÃ´ táº£ xÃ¡c suáº¥t chuyá»ƒn tá»« tráº¡ng thÃ¡i nÃ y sang tráº¡ng thÃ¡i khÃ¡c.*
*   **Equilibrium / Tráº¡ng thÃ¡i cÃ¢n báº±ng**: After a sufficiently large number of steps, the probability distribution of the states converges to a stable distribution.  
    *Sau má»™t sá»‘ bÆ°á»›c Ä‘á»§ lá»›n, phÃ¢n phá»‘i xÃ¡c suáº¥t cá»§a tráº¡ng thÃ¡i há»™i tá»¥ vá» má»™t phÃ¢n phá»‘i á»•n Ä‘á»‹nh, khÃ´ng thay Ä‘á»•i qua cÃ¡c bÆ°á»›c tiáº¿p theo.*

---

## 2. Monte Carlo Method (PhÆ°Æ¡ng phÃ¡p Monte Carlo)

Monte Carlo methods are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results.  
*PhÆ°Æ¡ng phÃ¡p Monte Carlo lÃ  má»™t nhÃ³m cÃ¡c thuáº­t toÃ¡n tÃ­nh toÃ¡n dá»±a vÃ o viá»‡c láº¥y máº«u ngáº«u nhiÃªn láº·p láº¡i Ä‘á»ƒ thu Ä‘Æ°á»£c cÃ¡c káº¿t quáº£ sá»‘.*

*   **Principle / NguyÃªn lÃ½**: Use randomness to solve problems that might be deterministic in principle.  
    *Sá»­ dá»¥ng tÃ­nh ngáº«u nhiÃªn Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh (deterministic) vá» nguyÃªn táº¯c.*
*   **Law of Large Numbers / Quy luáº­t sá»‘ lá»›n**: As the number of samples increases, the sample mean converges to the true expected value.  
    *Khi sá»‘ lÆ°á»£ng máº«u thá»­ nghiá»‡m tÄƒng lÃªn, káº¿t quáº£ trung bÃ¬nh cá»§a máº«u sáº½ há»™i tá»¥ vá» giÃ¡ trá»‹ ká»³ vá»ng thá»±c sá»±.*

---

## 3. Bayesian Inference (Suy luáº­n Bayesian)

Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available.  
*Suy luáº­n Bayes lÃ  phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª trong Ä‘Ã³ xÃ¡c suáº¥t Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘á»‹nh lÆ°á»£ng sá»± khÃ´ng cháº¯c cháº¯n. Äá»‹nh lÃ½ Bayes cáº­p nháº­t xÃ¡c suáº¥t cho má»™t giáº£ thuyáº¿t khi cÃ³ thÃªm báº±ng chá»©ng hoáº·c thÃ´ng tin má»›i.*

$$ P(\theta | D) = \frac{P(D | \theta) P(\theta)}{P(D)} $$

Where / Trong Ä‘Ã³:
*   $$P(\theta \mid D)$$: **Posterior** - Probability of parameter $$\theta$$ given data $$D$$. (*XÃ¡c suáº¥t cá»§a tham sá»‘ $$\theta$$ khi Ä‘Ã£ biáº¿t dá»¯ liá»‡u $$D$$.*)
*   $$P(D \mid \theta)$$: **Likelihood** - Probability of observing data $$D$$ given parameter $$\theta$$. (*XÃ¡c suáº¥t quan sÃ¡t dá»¯ liá»‡u $$D$$ náº¿u tham sá»‘ lÃ  $$\theta$$.*)
*   $$P(\theta)$$: **Prior** - Initial belief about $$\theta$$ before seeing data. (*Niá»m tin ban Ä‘áº§u vá» $$\theta$$ trÆ°á»›c khi tháº¥y dá»¯ liá»‡u.*)
*   $$P(D)$$: **Evidence** - Normalizing constant. (*Háº±ng sá»‘ chuáº©n hÃ³a, thÆ°á»ng ráº¥t khÃ³ tÃ­nh toÃ¡n trá»±c tiáº¿p trong khÃ´ng gian nhiá»u chiá»u.*)

---

## 4. Markov Chain Monte Carlo (MCMC)

### Why MCMC? / Táº¡i sao cáº§n MCMC?
In Bayesian statistics, calculating the posterior distribution $$P(\theta | D)$$ directly is often difficult because the denominator $$P(D)$$ requires integration over the entire parameter space.  
*Trong thá»‘ng kÃª Bayes, viá»‡c tÃ­nh toÃ¡n trá»±c tiáº¿p phÃ¢n phá»‘i háº­u nghiá»‡m $$P(\theta | D)$$ thÆ°á»ng gáº·p khÃ³ khÄƒn do máº«u sá»‘ $$P(D)$$ Ä‘Ã²i há»i tÃ­ch phÃ¢n qua toÃ n bá»™ khÃ´ng gian tham sá»‘ (vá»‘n cÃ³ thá»ƒ cÃ³ sá»‘ chiá»u ráº¥t lá»›n).*

MCMC solves this by sampling from the posterior distribution without calculating the normalizing constant $$P(D)$$.  
*MCMC giáº£i quyáº¿t váº¥n Ä‘á» nÃ y báº±ng cÃ¡ch láº¥y máº«u tá»« phÃ¢n phá»‘i háº­u nghiá»‡m mÃ  khÃ´ng cáº§n tÃ­nh háº±ng sá»‘ chuáº©n hÃ³a $$P(D)$$.*

### How it works / CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng
MCMC combines two methods:  
*MCMC káº¿t há»£p hai phÆ°Æ¡ng phÃ¡p:*
1.  **Monte Carlo**: Random sampling to estimate the distribution. (*Láº¥y máº«u ngáº«u nhiÃªn Ä‘á»ƒ Æ°á»›c lÆ°á»£ng phÃ¢n phá»‘i.*)
2.  **Markov Chain**: Generating dependent samples such that the limiting distribution is the target distribution. (*Táº¡o ra cÃ¡c máº«u phá»¥ thuá»™c nhau sao cho phÃ¢n phá»‘i giá»›i háº¡n cá»§a chuá»—i chÃ­nh lÃ  phÃ¢n phá»‘i má»¥c tiÃªu.*)

In other words, we design a "robot" that jumps randomly in the parameter space. The robot tends to stay longer in high-probability regions and visits low-probability regions less often.  
*Hay nÃ³i cÃ¡ch khÃ¡c, ta thiáº¿t káº¿ má»™t "con robot" nháº£y ngáº«u nhiÃªn trong khÃ´ng gian tham sá»‘. Con robot cÃ³ xu hÆ°á»›ng á»Ÿ láº¡i lÃ¢u hÆ¡n táº¡i nhá»¯ng vÃ¹ng cÃ³ xÃ¡c suáº¥t cao vÃ  Ã­t ghÃ© thÄƒm nhá»¯ng vÃ¹ng cÃ³ xÃ¡c suáº¥t tháº¥p. Dáº¥u váº¿t bÆ°á»›c chÃ¢n cá»§a robot chÃ­nh lÃ  cÃ¡c máº«u tá»« phÃ¢n phá»‘i cáº§n tÃ¬m.*

### Common Algorithms / CÃ¡c thuáº­t toÃ¡n phá»• biáº¿n
1.  **Metropolis-Hastings (MH)**: General algorithm, proposes jumps and accepts/rejects based on probability density ratio.  
    *Thuáº­t toÃ¡n tá»•ng quÃ¡t, Ä‘á» xuáº¥t bÆ°á»›c nháº£y vÃ  cháº¥p nháº­n/tá»« chá»‘i dá»±a trÃªn tá»· lá»‡ máº­t Ä‘á»™ xÃ¡c suáº¥t.*
2.  **Gibbs Sampling**: Special case of MH, updates one variable at a time while fixing others.  
    *TrÆ°á»ng há»£p Ä‘áº·c biá»‡t cá»§a MH, cáº­p nháº­t tá»«ng biáº¿n má»™t khi cá»‘ Ä‘á»‹nh cÃ¡c biáº¿n khÃ¡c.*
3.  **Hamiltonian Monte Carlo (HMC) / NUTS**: Uses gradients to propose more efficient jumps (used in Stan, PyMC3).  
    *Sá»­ dá»¥ng Ä‘áº¡o hÃ m (gradient) cá»§a hÃ m máº­t Ä‘á»™ Ä‘á»ƒ Ä‘á» xuáº¥t cÃ¡c bÆ°á»›c nháº£y hiá»‡u quáº£ hÆ¡n (ThÆ°á»ng Ä‘Æ°á»£c dÃ¹ng trong Stan, PyMC3).*
4.  **Affine Invariant Ensemble Sampler (emcee)**: Uses multiple "walkers" in parallel, efficient for skewed distributions.  
    *Sá»­ dá»¥ng nhiá»u "walkers" song song, hiá»‡u quáº£ cho cÃ¡c phÃ¢n phá»‘i mÃ©o mÃ³.*

---

## 5. Practical Applications / á»¨ng dá»¥ng thá»±c táº¿

### Civil Engineering & Project Management / Ká»¹ thuáº­t XÃ¢y dá»±ng & Quáº£n lÃ½ Dá»± Ã¡n
*   **Project Risk Analysis**: Simulating project completion time (PERT/CPM) when task durations are random variables. MCMC estimates the probability of deadline overrun.  
    *PhÃ¢n tÃ­ch rá»§i ro dá»± Ã¡n: MÃ´ phá»ng thá»i gian hoÃ n thÃ nh dá»± Ã¡n (PERT/CPM) khi thá»i gian tá»«ng tÃ¡c vá»¥ lÃ  biáº¿n ngáº«u nhiÃªn. MCMC giÃºp Æ°á»›c lÆ°á»£ng phÃ¢n phá»‘i xÃ¡c suáº¥t cá»§a ngÃ y hoÃ n thÃ nh.*
*   **Structural Reliability**: Assessment of structural failure probability under random loads (wind, earthquake) and uncertain material properties.  
    *Äá»™ tin cáº­y káº¿t cáº¥u: ÄÃ¡nh giÃ¡ xÃ¡c suáº¥t phÃ¡ há»§y cá»§a káº¿t cáº¥u chá»‹u táº£i trá»ng ngáº«u nhiÃªn (giÃ³, Ä‘á»™ng Ä‘áº¥t) vÃ  Ä‘áº·c trÆ°ng váº­t liá»‡u khÃ´ng cháº¯c cháº¯n.*
*   **Design Optimization**: Finding optimal design parameters in complex spaces.  
    *Tá»‘i Æ°u hÃ³a thiáº¿t káº¿: TÃ¬m kiáº¿m cÃ¡c tham sá»‘ thiáº¿t káº¿ tá»‘i Æ°u trong khÃ´ng gian phá»©c táº¡p.*

### Finance, Economics & Investment / TÃ i chÃ­nh, Kinh táº¿ & Äáº§u tÆ°
*   **Portfolio Optimization**: Estimating profit and risk distribution (VaR - Value at Risk). MCMC allows modeling of non-normal fat-tailed return distributions.  
    *Danh má»¥c Ä‘áº§u tÆ°: Æ¯á»›c lÆ°á»£ng phÃ¢n phá»‘i lá»£i nhuáº­n vÃ  rá»§i ro (VaR). MCMC cho phÃ©p mÃ´ hÃ¬nh hÃ³a cÃ¡c phÃ¢n phá»‘i lá»£i nhuáº­n Ä‘uÃ´i dÃ y (fat-tailed) phi chuáº©n, thá»±c táº¿ hÆ¡n so vá»›i giáº£ Ä‘á»‹nh phÃ¢n phá»‘i chuáº©n truyá»n thá»‘ng.*
*   **Stochastic Volatility**: Forecasting asset price volatility, options pricing.  
    *MÃ´ hÃ¬nh hÃ³a biáº¿n Ä‘á»™ng: Dá»± bÃ¡o biáº¿n Ä‘á»™ng giÃ¡ tÃ i sáº£n, Ä‘á»‹nh giÃ¡ quyá»n chá»n.*
*   **Algorithmic Trading**: Detecting regime switching to adjust automated trading strategies.  
    *Giao dá»‹ch thuáº­t toÃ¡n: PhÃ¡t hiá»‡n sá»± thay Ä‘á»•i cháº¿ Ä‘á»™ thá»‹ trÆ°á»ng (regime switching models) Ä‘á»ƒ Ä‘iá»u chá»‰nh chiáº¿n lÆ°á»£c giao dá»‹ch tá»± Ä‘á»™ng.*

---

## 6. Simulation Summary (TÃ³m táº¯t tÃ­nh toÃ¡n MÃ´ phá»ng)

This section summarizes a simple Metropolis-Hastings implementation to fit a linear model ($$y = mx + c$$) to noisy data.  
*Pháº§n nÃ y tÃ³m táº¯t quÃ¡ trÃ¬nh thá»±c hiá»‡n thuáº­t toÃ¡n Metropolis-Hastings Ä‘Æ¡n giáº£n Ä‘á»ƒ khá»›p mÃ´ hÃ¬nh Ä‘Æ°á»ng tháº³ng ($$y = mx + c$$) vÃ o dá»¯ liá»‡u nhiá»…u.*

### 6.1. Synthetic Data / Dá»¯ liá»‡u giáº£ Ä‘á»‹nh
Data generated with 30 points and error bars representing measurement uncertainty ($$\sigma=1$$).  
*Dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o ra vá»›i 30 Ä‘iá»ƒm. CÃ¡c thanh sai sá»‘ thá»ƒ hiá»‡n Ä‘á»™ khÃ´ng Ä‘áº£m báº£o Ä‘o ($$\sigma=1$$).*

<figure>
  <img src="{{ site.baseurl }}/assets/images/posts/2026-02-06-markov-chain-MC/mcmc_1_data.png" alt="Synthetic Data">
  <figcaption>Synthetic Data generated with noise.</figcaption>
</figure>

### 6.2. Chains / QuÃ¡ trÃ¬nh cháº¡y chuá»—i
The algorithm typically runs for 100,000 steps. The trace plot shows the value of `Slope` and `Intercept` over iterations.  
*Thuáº­t toÃ¡n cháº¡y 100,000 bÆ°á»›c. Biá»ƒu Ä‘á»“ Trace plot cho tháº¥y giÃ¡ trá»‹ cá»§a `Slope` vÃ  `Intercept` qua cÃ¡c bÆ°á»›c láº·p.*

<figure>
  <img src="{{ site.baseurl }}/assets/images/posts/2026-02-06-markov-chain-MC/mcmc_2_chains.png" alt="MCMC Chains">
  <figcaption>Trace plots for Slope and Intercept.</figcaption>
</figure>

### 6.3. Posterior Distributions / PhÃ¢n phá»‘i Háº­u nghiá»‡m
After removing the burn-in period, we obtain histograms of the parameters.  
*Sau khi loáº¡i bá» giai Ä‘oáº¡n Ä‘áº§u (burn-in), ta thu Ä‘Æ°á»£c phÃ¢n phá»‘i táº§n suáº¥t (Histogram) cá»§a cÃ¡c tham sá»‘.*

*   **Estimated Results / Káº¿t quáº£ Æ°á»›c lÆ°á»£ng**:
    *   Slope: ~1.40 (True: 1.5)
    *   Intercept: ~4.29 (True: 4.0)

<figure>
  <img src="{{ site.baseurl }}/assets/images/posts/2026-02-06-markov-chain-MC/mcmc_3_histograms.png" alt="Histograms">
  <figcaption>Posterior histograms.</figcaption>
</figure>

### 6.4. Correlation / TÆ°Æ¡ng quan tham sá»‘
Scatter plot showing dependence between `Slope` and `Intercept`. Negative correlation is observed.  
*Biá»ƒu Ä‘á»“ phÃ¢n tÃ¡n cho tháº¥y sá»± phá»¥ thuá»™c giá»¯a `Slope` vÃ  `Intercept`. CÃ³ sá»± tÆ°Æ¡ng quan Ã¢m: khi Ä‘á»™ dá»‘c tÄƒng, há»‡ sá»‘ cháº·n cÃ³ xu hÆ°á»›ng giáº£m.*

<figure>
  <img src="{{ site.baseurl }}/assets/images/posts/2026-02-06-markov-chain-MC/mcmc_4_correlation.png" alt="Correlation">
  <figcaption>Parameter correlation.</figcaption>
</figure>

### 6.5. Corner Plot
Corner plot showing marginal distributions on the diagonal and joint distributions off-diagonal.  
*Biá»ƒu Ä‘á»“ "Corner" thá»ƒ hiá»‡n Ä‘á»“ng thá»i phÃ¢n phá»‘i biÃªn trÃªn Ä‘Æ°á»ng chÃ©o vÃ  phÃ¢n phá»‘i Ä‘á»“ng thá»i ngoÃ i Ä‘Æ°á»ng chÃ©o.*

<figure>
  <img src="{{ site.baseurl }}/assets/images/posts/2026-02-06-markov-chain-MC/mcmc_5_corner.png" alt="Corner Plot">
  <figcaption>Corner plot using corner.py.</figcaption>
</figure>

### 6.6. Best Fit / Káº¿t quáº£ Khá»›p mÃ´ hÃ¬nh
The line with the highest Likelihood is plotted over the data.  
*ÄÆ°á»ng tháº³ng tá»« bá»™ tham sá»‘ cÃ³ Likelihood cao nháº¥t Ä‘Æ°á»£c váº½ chá»“ng lÃªn dá»¯ liá»‡u.*

<figure>
  <img src="{{ site.baseurl }}/assets/images/posts/2026-02-06-markov-chain-MC/mcmc_6_bestfit.png" alt="Best Fit">
  <figcaption>Best-fit model.</figcaption>
</figure>

### 6.7. Model Uncertainty / Äá»™ khÃ´ng Ä‘áº£m báº£o cá»§a mÃ´ hÃ¬nh
Visualizing a sample of lines from the MCMC chain reveals the model uncertainty.  
*Báº±ng cÃ¡ch váº½ ngáº«u nhiÃªn 100 Ä‘Æ°á»ng tháº³ng tá»« chuá»—i MCMC, ta hÃ¬nh dung Ä‘Æ°á»£c Ä‘á»™ khÃ´ng cháº¯c cháº¯n cá»§a mÃ´ hÃ¬nh.*

<figure>
  <img src="{{ site.baseurl }}/assets/images/posts/2026-02-06-markov-chain-MC/mcmc_7_uncertainty.png" alt="Uncertainty">
  <figcaption>Model uncertainty vizualization.</figcaption>
</figure>

---

## References / TÃ i liá»‡u tham kháº£o
1.  **Wikipedia - Markov chain Monte Carlo**: [https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)
2.  **Stanford CS109 - Mathematical Foundations**: [https://web.stanford.edu/class/archive/cs/cs109/cs109.1218/files/student_drive/9.6.pdf](https://web.stanford.edu/class/archive/cs/cs109/cs109.1218/files/student_drive/9.6.pdf)
